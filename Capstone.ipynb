{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different San Francisco Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries needed for the code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install lxml\n",
    "import requests\n",
    "import numpy as np\n",
    "!pip install sklearn\n",
    "!pip install folium\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading scrapped data from a spreadsheet about sanfraciso \n",
    "df = pd.read_csv('sfneighborhood.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foursquare credentials\n",
    "CLIENT_ID =  # your Foursquare ID\n",
    "CLIENT_SECRET =  # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch venues using the foursquare API\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500, LIMIT=50):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling venues near different SF neighborhood\n",
    "sf_venues = getNearbyVenues(names=df['NHOOD'],\n",
    "                                   latitudes=df['Latitude'],\n",
    "                                   longitudes=df['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot encoding of venues\n",
    "sf_onehot = pd.get_dummies(sf_venues[['Venue Category']], prefix=\"\",prefix_sep=\"\")\n",
    "sf_venues.reset_index()\n",
    "#tor_venues\n",
    "sf_onehot['Neighborhood'] = sf_venues['Neighborhood']\n",
    "\n",
    "first_column = sf_onehot.pop('Neighborhood')\n",
    "\n",
    "sf_onehot.insert(0, 'Neighborhood', first_column )\n",
    "\n",
    "sf_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping by neighborhood names\n",
    "sf_group = sf_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "sf_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging similar venue types into a single venue category like Restaurants, Schools, etc.\n",
    "\n",
    "df = sf_group.filter(regex='(Restaurant|Joint|Caf|Breakfast|Brewery|Deli|Diner)', axis=1).sum(axis=1)\n",
    "dfs = sf_group.filter(regex='(Store|Bakery)', axis=1).sum(axis=1)\n",
    "dfsh = sf_group.filter(regex='(Shop|Parlor|market|Supermarket|Market)', axis=1).sum(axis=1)\n",
    "dfsc = sf_group.filter(regex='School', axis=1).sum(axis=1)\n",
    "dfb = sf_group.filter(regex='(Bar|pub|Pub)', axis=1).sum(axis=1)\n",
    "dfg =sf_group.filter(regex='(Gym|gym|Yoga|Sports|Tennis|Center|Court|Field|Bike|Arcade|Studio)', axis=1).sum(axis=1)\n",
    "dfscenic = sf_group.filter(regex='(Trail|Beach|Hill|Park|)', axis=1).sum(axis=1)\n",
    "dfbank = sf_group.filter(regex='(ATM|Bank)', axis=1).sum(axis=1)\n",
    "dfart = sf_group.filter(regex='(Art|Museum|Gallery)', axis=1).sum(axis=1)\n",
    "dftransport = sf_group.filter(regex='(Bus|Station|Stop|Line|Train|Airport)', axis=1).sum(axis=1)\n",
    "dfent = sf_group.filter(regex='(Movie|Theatre|Concert)', axis=1).sum(axis=1)\n",
    "\n",
    "sf_group.drop(list(sf_group.filter(regex='(Restaurant|Joint|Caf|Breakfast|Brewery|Deli|Diner)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(Store|Bakery)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(Shop|Parlor|market|Supermarket|Market)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='School')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(Bar|pub|Pub)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(Gym|gym|Yoga|Sports|Tennis|Center|Court|Field|Bike|Arcade|Studio)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(Trail|Beach|Hill|Park)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(ATM|Bank)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(Art|Museum|Gallery)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(Bus|Station|Stop|Line|Train|Airport)')), axis=1, inplace=True)\n",
    "sf_group.drop(list(sf_group.filter(regex='(Movie|Theatre|Concert)')), axis=1, inplace=True)\n",
    "\n",
    "sf_group['Restaurants'] = df\n",
    "sf_group['Stores'] = dfs\n",
    "sf_group['Shops'] = dfsh\n",
    "sf_group['Schools'] = dfsc\n",
    "sf_group['Bars'] = dfb\n",
    "sf_group['Recretional'] = dfg\n",
    "sf_group['Arts'] = dfart\n",
    "sf_group['Bank'] = dfbank\n",
    "sf_group['Nature'] = dfscenic\n",
    "sf_group['Transport'] = dftransport\n",
    "sf_group['Entertainment'] = dfent\n",
    "sf_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe with only lumped categorical columns\n",
    "sf_cats = sf_group[['Neighborhood','Restaurants','Stores','Shops','Schools','Bars','Recretional', 'Arts', 'Bank', 'Nature', 'Transport', 'Entertainment']].copy()\n",
    "sf_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe Nature category has similar mean for every Neiborhood so dropping this coulumn so to not skew the clustering\n",
    "sf_cats.drop('Nature', axis=1, inplace=True)\n",
    "sf_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding and normalizing the Rent, House Price and Crime Rate columns\n",
    "sf_cats['Rent'] = df['Rent']/(df['Rent'].max()*10)\n",
    "sf_cats['House Price'] = df['House Price']/(df['House Price'].max()*10)\n",
    "sf_cats['Crime Rate'] = df['Crime Rate']/(df['Crime Rate'].max()*10)\n",
    "sf_cats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Neighborhood columns for clustering features\n",
    "sf_group_clustering = sf_cats.drop('Neighborhood', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best K from the Elbow method\n",
    "wcss=[]\n",
    "\n",
    "\n",
    "for i in range(1,9):\n",
    "    kmeans = KMeans(n_clusters=i, init ='k-means++', max_iter=300,  n_init=10,random_state=0 )\n",
    "    kmeans.fit(sf_group_clustering)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(range(1,9), wcss)\n",
    "plt.title('Elbow Graph')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set number of clusters based of the elbow method\n",
    "kclusters = 5\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, init ='k-means++', max_iter=300,  n_init=10,random_state=0).fit(sf_group_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:31] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the cluster labels to the dataframe\n",
    "sf_cats.insert(1, 'Cluster Labels', kmeans.labels_)\n",
    "sf_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to show how Kmeans captured the relation between Crime Rate and House Price\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "sns.barplot(data=sf_cats, x='Cluster Labels', y='Crime Rate', ax= axs[0])\n",
    "sns.barplot(data=sf_cats, x='Cluster Labels', y='House Price', ax=axs[1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pairplot to find relation between different factors\n",
    "sns.pairplot(sf_cats[['House Price', 'Rent', 'Crime Rate', 'Restaurants', 'Cluster Labels']], diag_kind='hist' , hue='Cluster Labels', size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding absolute values and lat lon\n",
    "sf_cats['Latitude'] = df['Latitude']\n",
    "sf_cats['Longitude'] = df['Longitude']\n",
    "sf_cats['House Price Value'] = df['House Price']\n",
    "sf_cats['Rent Value'] = df['Rent']\n",
    "sf_cats['Crime Rate%'] = df['Crime Rate']\n",
    "sf_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map of the city of San Francisco and plotting them\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "map_clusters = folium.Map(location=[37.73, -122.44], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster, hp, ren, cr in zip(sf_cats['Latitude'], sf_cats['Longitude'], sf_cats['Neighborhood'], sf_cats['Cluster Labels'], sf_cats['House Price Value'], sf_cats['Rent Value'], sf_cats['Crime Rate%']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster) + ' Avg House Price ' + str(hp) + ' Avg Rent ' + str(ren) + ' Crime Rate ' + str(cr), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
